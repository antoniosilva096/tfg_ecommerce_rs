# -*- coding: utf-8 -*-
"""procesar_dataset_productos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QwXCLWVkQXjldSS8QXtK1n78MIZdN1Mm
"""

!pip install datasets pandas nltk

import pandas as pd
import re
import nltk
from datasets import load_dataset

# Descargar stopwords de nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
STOPWORDS = set(stopwords.words('english'))

print("Librerías importadas y stopwords descargadas.")

# Expresiones regulares para limpieza
RE_NON_ALPHANUM = re.compile(r'[^A-Za-z0-9.]')
RE_WHITESPACE = re.compile(r'\s+')

def text_cleaning(text: str) -> str:
    """
    Limpia el texto: lo convierte a minúsculas, elimina caracteres no alfanuméricos (excepto el punto)
    y normaliza espacios.
    """
    text = text.strip().lower()
    text = RE_NON_ALPHANUM.sub(' ', text)
    text = RE_WHITESPACE.sub(' ', text)
    return text.strip()

def process_categories(cat):
    """
    Si 'categories' es una lista, une sus elementos aplicando limpieza;
    de lo contrario, limpia la cadena directamente.
    """
    if isinstance(cat, list):
        return ", ".join([text_cleaning(item) for item in cat])
    return text_cleaning(cat)

# Carga el dataset en modo streaming para evitar sobrecargar la RAM
dataset = load_dataset(
    "McAuley-Lab/Amazon-Reviews-2023",
    "raw_meta_Electronics",
    split="full",
    streaming=True,
    trust_remote_code=True
)
print("Dataset cargado en modo streaming.")

import csv

output_path = "products_clean.csv"
target_records = 150000  # Número de registros deseados
count = 0

with open(output_path, mode="w", encoding="utf-8", newline="") as csvfile:
    fieldnames = ["asin", "title", "categories", "price", "average_rating"]
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
    writer.writeheader()

    for example in dataset:
        # Verificar que existan los campos imprescindibles: 'title', 'categories', 'price' y 'average_rating'
        if not (example.get("title") and example.get("categories") and example.get("price") and example.get("average_rating")):
            continue

        # Convertir 'price' a float
        try:
            price = float(example["price"])
        except:
            continue

        # Convertir 'average_rating' a float
        try:
            avg_rating = float(example["average_rating"])
        except:
            continue

        # Procesar título y categorías
        title = text_cleaning(example["title"])
        categories = process_categories(example["categories"])

        # Utilizar 'parent_asin' como identificador único (asin)
        asin = example.get("parent_asin", "")

        writer.writerow({
            "asin": asin,
            "title": title,
            "categories": categories,
            "price": price,
            "average_rating": avg_rating
        })
        count += 1

        if count >= target_records:
            break

print(f"Exportados {count} registros a {output_path}")

from google.colab import files
files.download(output_path)